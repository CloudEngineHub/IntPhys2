{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc7c25b-eefc-432c-9afb-ab3ef6b81296",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8361e133-d48e-42a5-8633-890f538a131d",
   "metadata": {},
   "outputs": [],
   "source": [
    "YOUR_INTPHYS2_PATH = \"\"\n",
    "YOUR_MODEL_PREDICTION_PATH = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fd337a-5c54-4779-9f0b-0c2db56cedb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(df_merged, df_gt_labels, col1, col2):\n",
    "  \"\"\"\n",
    "  Calculates the accuracy between two columns in a Pandas DataFrame.\n",
    "\n",
    "  Args:\n",
    "    df: The Pandas DataFrame.\n",
    "    col1: The name of the first column.\n",
    "    col2: The name of the second column.\n",
    "\n",
    "  Returns:\n",
    "    The accuracy as a float.\n",
    "  \"\"\"\n",
    "  incorrect_predictions = (df_merged[col1] == 2).sum()\n",
    "  correct_predictions = (df_merged[col1] == df_merged[col2]).sum()\n",
    "  total_predictions = len(df_gt_labels)\n",
    "  accuracy = correct_predictions / float(total_predictions)\n",
    "  return (accuracy, int(correct_predictions), int(total_predictions), int(incorrect_predictions))\n",
    "\n",
    "\n",
    "\n",
    "def label_pred_yes_no(row):\n",
    "    if \"yes\" in str(row[\"response\"]) or \"Yes\" in str(row[\"response\"]):\n",
    "        return 1\n",
    "    elif \"no\" in str(row[\"response\"]) or \"No\" in str(row[\"response\"]):\n",
    "        return 0\n",
    "    else:\n",
    "        #print(\"Not found\", str(row[\"response\"]))\n",
    "        return 2\n",
    "\n",
    "def label_pred_1_0(row):\n",
    "    if \"1\" in str(row[\"response\"]):\n",
    "        return 1\n",
    "    elif \"0\" in str(row[\"response\"]):\n",
    "        return 0\n",
    "    else:\n",
    "        #print(\"Not found\", str(row[\"response\"]))\n",
    "        return 2\n",
    "        \n",
    "def label_target(row):\n",
    "    if \"Impossible\" in row[\"type\"]:\n",
    "        return 0\n",
    "    elif \"Possible\" in row[\"type\"]:\n",
    "        return 1\n",
    "    else:\n",
    "        print(\"Parsing Error!\")\n",
    "\n",
    "def get_values_singlevideo(model, source=\"Main\", split=\"\", subsplit='', fps=15, prompt=0, seed=1):\n",
    "    ground_truth_labels = YOUR_INTPHYS2_PATH+source+\"/metadata.csv\"\n",
    "    if model == \"Qwen2_5_VL\":\n",
    "        filecsv = YOUR_MODEL_PREDICTION_PATH+str(seed)+\"prompt\"+str(prompt)+\"_\"+source+\"_\"+model+\"_\"+str(fps)+\"fps.csv\"\n",
    "    else:\n",
    "        filecsv = YOUR_MODEL_PREDICTION_PATH+str(seed)+\"prompt\"+str(prompt)+\"_\"+source+\"_\"+model+\"_\"+str(fps)+\"fps.csv\"\n",
    "    predicted_labels = pd.read_csv(filecsv)\n",
    "    predicted_labels['filename'] = predicted_labels['filename'].str.replace('.mp4', '', regex=False)\n",
    "    if model == \"Qwen2_5_VL\" or model == \"Perception-LM-3B\" :\n",
    "        predicted_labels['filename'] = predicted_labels['filename'].str.split('/')\n",
    "        predicted_labels['filename'] = predicted_labels['filename'].str[-1]\n",
    "\n",
    "    df_gt_labels = pd.read_csv(ground_truth_labels)\n",
    "    df_gt_labels = df_gt_labels.rename(columns={'name': 'filename'})\n",
    "\n",
    "    predicted_labels.filename = predicted_labels.filename.astype(str)\n",
    "    df_gt_labels.filename = df_gt_labels.filename.astype(str)\n",
    "\n",
    "    # Split difficulty on Main\n",
    "    if source == 'Main':\n",
    "        if subsplit == \"Easy\":\n",
    "            df_gt_labels = df_gt_labels.loc[df_gt_labels['env'].isin(['BasicLevel_0'])]\n",
    "        elif subsplit == \"Medium\":\n",
    "            df_gt_labels = df_gt_labels.loc[df_gt_labels['env'].isin([\"SaltFlats_0\", \"DesertMap_0\", \"RaceTrack_0\", \"TropicalIsland_0\"])]\n",
    "        elif subsplit == \"Hard\":\n",
    "            df_gt_labels = df_gt_labels.loc[df_gt_labels['env'].isin([\"PLVDaylight_0\", \"Egypt_0\", \"RuralAustralia03_0\", \"ParkingGarage_0\", \"None\"])]\n",
    "    \n",
    "    if source == 'Main':\n",
    "        # Camera settings\n",
    "        if split == 'FixedCamera':\n",
    "            df_gt_labels = df_gt_labels.loc[df_gt_labels['game_name'].isin([\"FixedMarryPoppins\", \"FixedJumpSolidity\", \"RotatingCup\", \"HotAirBallon\", \"SphereFallingDown\", \"SolidityFallingFlat\"])]            \n",
    "        elif split == 'MovingCamera':\n",
    "            df_gt_labels = df_gt_labels.loc[df_gt_labels['game_name'].isin([\"SphereFallingDownSoldity\", \"BoxSoldity\", \"Scaffoling\", \"CameraSolidity\", \"JumpSolidity\", \"Box\", \"MovingAroundOccluder\", \"JailStone\", \"PrisonCell\", \"Restaurant\"])]            \n",
    "\n",
    "        # Properties settings\n",
    "        if subsplit == 'Permanence':\n",
    "            df_gt_labels = df_gt_labels.loc[df_gt_labels['condition'].isin([\"permanence\"])]            \n",
    "        elif subsplit == 'Immutability':\n",
    "            df_gt_labels = df_gt_labels.loc[df_gt_labels['condition'].isin([\"immutability\", \"immutability_texture\"])]            \n",
    "        elif subsplit == 'Continuity':\n",
    "            df_gt_labels = df_gt_labels.loc[df_gt_labels['condition'].isin([\"continuity\", \"continuity_swap\"])]            \n",
    "        elif subsplit == 'Solidity':\n",
    "            df_gt_labels = df_gt_labels.loc[df_gt_labels['condition'].isin([\"solidity\"])]            \n",
    "\n",
    "\n",
    "    df_merged = predicted_labels.merge(df_gt_labels, on='filename')\n",
    "    df_merged[\"target\"] = df_merged.apply(label_target, axis=1)\n",
    "    if prompt == 0 or prompt == 2 or prompt == 4 or prompt == 5 or prompt == 6:\n",
    "        df_merged[\"response\"] = df_merged.apply(label_pred_yes_no, axis=1)\n",
    "    else:\n",
    "        df_merged[\"response\"] = df_merged.apply(label_pred_1_0, axis=1)\n",
    "    df_merged = df_merged[['SceneIndex', 'filename', \"target\", \"response\", \"env\"]]#.\n",
    "\n",
    "    return calculate_accuracy(df_merged, df_gt_labels, \"response\", \"target\"), filecsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8feb8589-e1e2-4740-8d65-aa1138cb2229",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_data = []\n",
    "for i, model in enumerate([\"gemini-1.5-pro\"]):\n",
    "    new_dict = {}\n",
    "    list_accs = []\n",
    "    list_accs_final = []\n",
    "    for split in [\"Permanence\", \"Immutability\", \"Continuity\", \"Solidity\"]:\n",
    "    #for split in [\"Easy\", \"Medium\", \"Hard\", \"All\"]:\n",
    "        list_split_res = []\n",
    "        list_files = []\n",
    "        for camera in [\"FixedCamera\", \"MovingCamera\", \"All\"]:\n",
    "            for prompt in [0]:\n",
    "                for seed in [1]:\n",
    "                    list_frames = [1]\n",
    "                    for frame_number in list_frames:\n",
    "                        # print(model, split)\n",
    "                        all, filecsv = get_values_singlevideo(model, \"Main\", camera, split, fps=frame_number, prompt=prompt, seed=seed)\n",
    "                        accuracy, correct_predictions, total_predictions, incorrect_predictions = all\n",
    "                        list_files.append(filecsv)\n",
    "                        list_accs.append(accuracy)\n",
    "                        list_split_res.append(accuracy * 100)\n",
    "            new_dict[split] = (np.max(list_split_res),np.std(list_accs))\n",
    "            max_elem = np.argmax(list_split_res)\n",
    "            print(camera, model, \" \", split, \" \", np.max(list_split_res), list_files[max_elem])\n",
    "            list_accs_final.append(list_split_res[max_elem])\n",
    "    print(model)\n",
    "    s_results = \"\"\n",
    "    for acc in list_accs_final:\n",
    "        s_results += \"{:.2f} & \".format(acc)\n",
    "    print(s_results)\n",
    "    list_data.append(new_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db543353-615b-455b-a019-267609761be2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
